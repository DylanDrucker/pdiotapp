{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcad8c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages (from scikit-learn) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d75005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059ced82",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_labels = []\n",
    "data = []\n",
    "\n",
    "features_accelometer = ['accel_x','accel_y','accel_z']\n",
    "\n",
    "data_path = 'clean_respeck_normal'\n",
    "\n",
    "for filename in os.listdir(data_path):\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    # extract activity label from the filename\n",
    "    activity = filename.split('_')[3]\n",
    "    #create a df with the accelometer data\n",
    "    df = pd.read_csv(file_path).loc[:, features_accelometer]\n",
    "    \n",
    "    #appends data and labels\n",
    "    #print(filename)\n",
    "    #print(df.values.shape)\n",
    "    data.append(df.values)\n",
    "    activity_labels.append(activity)\n",
    "    \n",
    "#convert to numpy arrays for the model\n",
    "data_array = np.array(data)\n",
    "labels_array = np.array(activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0517653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all elemets in the array are of the same shape\n",
    "first_element_shape = data_array[0].shape\n",
    "\n",
    "all(record.shape == first_element_shape for record in data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2377be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different shapes in the array:\n",
      "(125, 3)\n"
     ]
    }
   ],
   "source": [
    "# get the different shapes in the array\n",
    "\n",
    "unique_shapes = set()\n",
    "\n",
    "# Iterate through the elements and add their shapes to the set\n",
    "for record in data_array:\n",
    "    unique_shapes.add(record.shape)\n",
    "\n",
    "# Print out the unique shapes\n",
    "print(\"Different shapes in the array:\")\n",
    "for shape in unique_shapes:\n",
    "    print(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98121952",
   "metadata": {},
   "source": [
    "## preparing data for the model\n",
    "#### encoding labels\n",
    "#### train test and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdbc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels to numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2375a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (715, 125, 3)\n",
      "y_train shape: (715,)\n",
      "X_test shape: (179, 125, 3)\n",
      "y_test shape: (179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_array, y, \n",
    "                                                    test_size =0.2, random_state=0,\n",
    "                                                   stratify=y)\n",
    "# Check the shapes of the resulting arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c57467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_val shape: (572, 125, 3)\n",
      "y_train_val shape: (572,)\n",
      "X_val shape: (143, 125, 3)\n",
      "y_val shape: (143,)\n"
     ]
    }
   ],
   "source": [
    "#create a validation set for the CNN\n",
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size = 0.2, random_state=0,\n",
    "                                                         stratify=y_train)\n",
    "print(\"X_train_val shape:\", X_train_val.shape)\n",
    "print(\"y_train_val shape:\", y_train_val.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8fd1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fde9103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the number of unique activity labels in the whole set training and testing\n",
    "num_activities = len(set(activity_labels))\n",
    "num_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa45c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy, epochs, batch_size):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    #1D convolutional layer\n",
    "    model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(125,3)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    #flatten before the fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    #add a fully connected layer with 128 units\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    \n",
    "    #add output layer\n",
    "    model.add(layers.Dense(num_activities, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    history=model.fit(X_train_val, y_train_val, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f'Test accuracy: {test_accuracy *100:.2f}%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed3e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 123, 32)           320       \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 61, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1952)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               249984    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251,852\n",
      "Trainable params: 251,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 1.6496 - accuracy: 0.4913 - val_loss: 1.1825 - val_accuracy: 0.6014\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9327 - accuracy: 0.6556 - val_loss: 0.9405 - val_accuracy: 0.6224\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7216 - accuracy: 0.7238 - val_loss: 0.8538 - val_accuracy: 0.6573\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.7168 - val_loss: 0.8355 - val_accuracy: 0.6503\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5674 - accuracy: 0.7675 - val_loss: 0.6811 - val_accuracy: 0.7692\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.8112 - val_loss: 0.6091 - val_accuracy: 0.7902\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8794 - val_loss: 0.6104 - val_accuracy: 0.7762\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8811 - val_loss: 0.5531 - val_accuracy: 0.7832\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3224 - accuracy: 0.9126 - val_loss: 0.4992 - val_accuracy: 0.8252\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2773 - accuracy: 0.9318 - val_loss: 0.5166 - val_accuracy: 0.8322\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7877\n",
      "Test accuracy: 78.77%%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e7e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c613f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 1s 54ms/step - loss: 2.3738 - accuracy: 0.1678 - val_loss: 2.1272 - val_accuracy: 0.4126\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.9945 - accuracy: 0.3944 - val_loss: 1.7595 - val_accuracy: 0.4126\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.6414 - accuracy: 0.4853 - val_loss: 1.4216 - val_accuracy: 0.5804\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3368 - accuracy: 0.5748 - val_loss: 1.2082 - val_accuracy: 0.6853\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.1508 - accuracy: 0.6294 - val_loss: 1.0585 - val_accuracy: 0.6853\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0129 - accuracy: 0.6448 - val_loss: 0.9257 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9123 - accuracy: 0.6685 - val_loss: 0.8363 - val_accuracy: 0.6993\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8333 - accuracy: 0.6909 - val_loss: 0.7712 - val_accuracy: 0.7343\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7862 - accuracy: 0.7007 - val_loss: 0.7316 - val_accuracy: 0.7063\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7577 - accuracy: 0.6979 - val_loss: 0.6893 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6979 - accuracy: 0.7189 - val_loss: 0.6536 - val_accuracy: 0.7483\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6634 - accuracy: 0.7385 - val_loss: 0.6166 - val_accuracy: 0.7343\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6385 - accuracy: 0.7427 - val_loss: 0.5932 - val_accuracy: 0.7413\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6027 - accuracy: 0.7580 - val_loss: 0.5621 - val_accuracy: 0.7972\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5733 - accuracy: 0.7664 - val_loss: 0.5279 - val_accuracy: 0.7902\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5523 - accuracy: 0.8000 - val_loss: 0.5018 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5332 - accuracy: 0.7958 - val_loss: 0.4809 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4869 - accuracy: 0.8252 - val_loss: 0.4481 - val_accuracy: 0.8741\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4713 - accuracy: 0.8545 - val_loss: 0.4186 - val_accuracy: 0.8811\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4523 - accuracy: 0.8587 - val_loss: 0.3932 - val_accuracy: 0.8811\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8492\n",
      "Test accuracy: 84.92%%\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(125,3)),\n",
    "    keras.layers.Conv1D(32, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(12, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile model with loss, optimiser, and metrics\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 20 epochs with batch size 128\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                    epochs=epochs, validation_data=(X_val, y_val))\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "print(f'Test accuracy: {test_accuracy *100:.2f}%%')\n",
    "\n",
    "model.save('sequential_CNN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8aef4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\1juli\\AppData\\Local\\Temp\\tmpaegvf29s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\1juli\\AppData\\Local\\Temp\\tmpaegvf29s\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model('sequential_CNN.h5')\n",
    "\n",
    "#convert to TensorFLowLite\n",
    "conv = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = conv.convert()\n",
    "\n",
    "with open('sequential_CNN.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac446b8",
   "metadata": {},
   "source": [
    "## Grid search: optimize mode with different parameters\n",
    "\n",
    "code for the grid search adapted from https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba7b9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff2ed81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10,50,100]\n",
    "optimizer = ['Adam', 'SGD', 'Adamax']\n",
    "activation = ['relu', 'sigmoid']\n",
    "\n",
    "param_grid={\n",
    "    #'batch_size': batch_size,\n",
    "           'optimizer': optimizer}\n",
    "          # 'activation': activation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475e39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "C:\\Users\\1juli\\anaconda3\\envs\\pdiot\\lib\\site-packages\\scikeras\\wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'optimizer': 'Adamax'}\n",
      "Best accuracy: 81.40%\n"
     ]
    }
   ],
   "source": [
    "# model with placeholders for parameters\n",
    "def create_model(optimizer='adam', activation = 'relu'):\n",
    "    model=keras.Sequential([\n",
    "    keras.Input(shape=(125,3)),\n",
    "    keras.layers.Conv1D(32, kernel_size=3, activation=activation),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation=activation),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(12, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "seed=0\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "grid=GridSearchCV(estimator=model, param_grid=param_grid,cv=3)\n",
    "\n",
    "#model.get_params().keys()\n",
    "\n",
    "grid_results = grid.fit(X_train, y_train)\n",
    "# Print the best parameters and results\n",
    "print(f'Best parameters: {grid_results.best_params_}')\n",
    "print(f'Best accuracy: {grid_results.best_score_ * 100:.2f}%')\n",
    "\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8280d62",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46df7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.664804469273743"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#support vector classifier\n",
    "\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "linear_svm = SVC(kernel='linear')\n",
    "linear_svm.fit(X_train_flat, y_train)\n",
    "y_pred = linear_svm.predict(X_test_flat)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13dcd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of polynomial svm 0.7150837988826816\n",
      "accuracy of sigmoid svm 0.5195530726256983\n"
     ]
    }
   ],
   "source": [
    "poly_svm = SVC(kernel='poly')\n",
    "poly_svm.fit(X_train_flat, y_train)\n",
    "y_pred = poly_svm.predict(X_test_flat)\n",
    "print('accuracy of polynomial svm', accuracy_score(y_test, y_pred))\n",
    "\n",
    "sig_svm = SVC(kernel='sigmoid', gamma='scale')\n",
    "sig_svm.fit(X_train_flat, y_train)\n",
    "y_pred = sig_svm.predict(X_test_flat)\n",
    "print('accuracy of sigmoid svm', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26875629",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "with different criteria and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fc153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "max_depth = [3, 4, 5, 6, 7, 8, 9]\n",
    "model = DecisionTreeClassifier()\n",
    "grid = dict(criterion = criteria, max_depth = max_depth)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, scoring='accuracy', verbose=1)\n",
    "grid_result = grid_search.fit(X_train_flat, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D model for using accelometer and gyroscope\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#define CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer: adjust to the shape of data\n",
    "model.add(layers.InputLayer(input_shape=(window_size, num_sensor_features, 1)))\n",
    "\n",
    "#conv layers\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#flatten output\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#fully connected layers \n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) #for regularisation\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#display model summary\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(train_data, train_labels, epochs=num_epochs, batch_size=batch_size,\n",
    "                 validation_data=(validation_data, validation_labels))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "#predictions for a given data with the size of the window\n",
    "#predictions = model.predict(input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
